{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "# https://colab.research.google.com/drive/1uFJBO1pgsiFwCGIJwZlhUzaJ2srDbtw-#scrollTo=LjMMYJv85hVT\n",
    "# https://www.tensorflow.org/tutorials/text/nmt_with_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import unicodedata\n",
    "import re\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(loc = '../input/spa-eng/spa.txt', num_samples = 30000 ):\n",
    "    file = open(loc, encoding='UTF-8').read().strip().split('\\n')  \n",
    "    original_word_pairs = [[w for w in l.split('\\t')] for l in file[:num_samples]]\n",
    "    data = pd.DataFrame(original_word_pairs, columns=[\"eng\", \"es\"])\n",
    "    return data\n",
    "\n",
    "# Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "    \"\"\"\n",
    "    Normalizes latin chars with accent to their canonical decomposition\n",
    "    \"\"\"\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "    \n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\" \n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    \n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w = w.rstrip().strip()\n",
    "    \n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageIndex():\n",
    "    def __init__(self, lang):\n",
    "        \"\"\" lang are the list of phrases from each language\"\"\"\n",
    "        self.lang = lang\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.vocab = set()\n",
    "        \n",
    "        self.create_index()\n",
    "        \n",
    "    def create_index(self):\n",
    "        for phrase in self.lang:\n",
    "            # update with individual tokens\n",
    "            self.vocab.update(phrase.split(' '))\n",
    "            \n",
    "        # sort the vocab\n",
    "        self.vocab = sorted(self.vocab)\n",
    "\n",
    "        # add a padding token with index 0\n",
    "        self.word2idx['<pad>'] = 0\n",
    "        \n",
    "        # word to index mapping\n",
    "        for index, word in enumerate(self.vocab):\n",
    "            self.word2idx[word] = index + 1 # +1 because of pad token\n",
    "        \n",
    "        # index to word mapping\n",
    "        for word, index in self.word2idx.items():\n",
    "            self.idx2word[index] = word        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>es</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Ve.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vete.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vaya.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Váyase.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Hola.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Run!</td>\n",
       "      <td>¡Corre!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Run.</td>\n",
       "      <td>Corred.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Who?</td>\n",
       "      <td>¿Quién?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fire!</td>\n",
       "      <td>¡Fuego!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fire!</td>\n",
       "      <td>¡Incendio!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     eng          es\n",
       "0    Go.         Ve.\n",
       "1    Go.       Vete.\n",
       "2    Go.       Vaya.\n",
       "3    Go.     Váyase.\n",
       "4    Hi.       Hola.\n",
       "5   Run!     ¡Corre!\n",
       "6   Run.     Corred.\n",
       "7   Who?     ¿Quién?\n",
       "8  Fire!     ¡Fuego!\n",
       "9  Fire!  ¡Incendio!"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data()\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>es</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29607</th>\n",
       "      <td>&lt;start&gt; tom has three cousins . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; tom tiene tres primos . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>&lt;start&gt; tell us more . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; cuentanos mas . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11641</th>\n",
       "      <td>&lt;start&gt; the book is here . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; el libro esta aqui . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13938</th>\n",
       "      <td>&lt;start&gt; it s dark outside . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; esta oscuro fuera . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12821</th>\n",
       "      <td>&lt;start&gt; do you have a car ? &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; ¿ tienes auto ? &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8565</th>\n",
       "      <td>&lt;start&gt; it s not so far . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; no esta tan lejos . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16272</th>\n",
       "      <td>&lt;start&gt; i already said yes . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; ya dije que si . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16472</th>\n",
       "      <td>&lt;start&gt; i have cabin fever . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; tengo miedo a los lugares cerrados . &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19393</th>\n",
       "      <td>&lt;start&gt; don t ever doubt it . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; ni lo dudes . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23757</th>\n",
       "      <td>&lt;start&gt; i drank from the tap . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; he bebido de la canilla . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         eng  \\\n",
       "29607  <start> tom has three cousins . <end>   \n",
       "3257            <start> tell us more . <end>   \n",
       "11641       <start> the book is here . <end>   \n",
       "13938      <start> it s dark outside . <end>   \n",
       "12821      <start> do you have a car ? <end>   \n",
       "8565         <start> it s not so far . <end>   \n",
       "16272     <start> i already said yes . <end>   \n",
       "16472     <start> i have cabin fever . <end>   \n",
       "19393    <start> don t ever doubt it . <end>   \n",
       "23757   <start> i drank from the tap . <end>   \n",
       "\n",
       "                                                      es  \n",
       "29607              <start> tom tiene tres primos . <end>  \n",
       "3257                       <start> cuentanos mas . <end>  \n",
       "11641                 <start> el libro esta aqui . <end>  \n",
       "13938                  <start> esta oscuro fuera . <end>  \n",
       "12821                      <start> ¿ tienes auto ? <end>  \n",
       "8565                   <start> no esta tan lejos . <end>  \n",
       "16272                     <start> ya dije que si . <end>  \n",
       "16472  <start> tengo miedo a los lugares cerrados . <...  \n",
       "19393                        <start> ni lo dudes . <end>  \n",
       "23757            <start> he bebido de la canilla . <end>  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we do the preprocessing using pandas and lambdas\n",
    "data[\"eng\"] = data.eng.apply(lambda w: preprocess_sentence(w))\n",
    "data[\"es\"] = data.es.apply(lambda w: preprocess_sentence(w))\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 9090, 3, 4],\n",
       " [5, 9204, 3, 4],\n",
       " [5, 9082, 3, 4],\n",
       " [5, 9089, 3, 4],\n",
       " [5, 4702, 3, 4],\n",
       " [5, 2299, 1, 4],\n",
       " [5, 2304, 3, 4],\n",
       " [5, 9413, 7433, 6, 4],\n",
       " [5, 4270, 1, 4],\n",
       " [5, 4881, 1, 4]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index language using the class above\n",
    "inp_lang = LanguageIndex(data[\"es\"].values.tolist())\n",
    "targ_lang = LanguageIndex(data[\"eng\"].values.tolist())\n",
    "# Vectorize the input and target languages\n",
    "input_tensor = [[inp_lang.word2idx[s] for s in es.split(' ')]  for es in data[\"es\"].values.tolist()]\n",
    "target_tensor = [[targ_lang.word2idx[s] for s in eng.split(' ')]  for eng in data[\"eng\"].values.tolist()]\n",
    "input_tensor[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 1857, 3, 4],\n",
       " [5, 1857, 3, 4],\n",
       " [5, 1857, 3, 4],\n",
       " [5, 1857, 3, 4],\n",
       " [5, 2058, 3, 4],\n",
       " [5, 3655, 1, 4],\n",
       " [5, 3655, 3, 4],\n",
       " [5, 4815, 6, 4],\n",
       " [5, 1636, 1, 4],\n",
       " [5, 1636, 1, 4]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tensor[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the max_length of input and output tensor\n",
    "max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(x, max_len):\n",
    "    padded = np.zeros((max_len), dtype=np.int64)\n",
    "    if len(x) > max_len: padded[:] = x[:max_len]\n",
    "    else: padded[:len(x)] = x\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inplace padding\n",
    "input_tensor = [pad_sequences(x, max_length_inp) for x in input_tensor]\n",
    "target_tensor = [pad_sequences(x, max_length_tar) for x in target_tensor]\n",
    "len(target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   5, 1857,    3,    4,    0,    0,    0,    0,    0,    0,    0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_length_inp : 16\n",
      "max_length_tar : 11\n"
     ]
    }
   ],
   "source": [
    "print(\"max_length_inp :\", max_length_inp)\n",
    "print(\"max_length_tar :\",max_length_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24000, 24000, 6000, 6000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.data = X\n",
    "        self.target = y\n",
    "        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "        x_len = self.length[index]\n",
    "        return x,y,x_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dat = MyData(input_tensor_train, target_tensor_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word2idx)\n",
    "vocab_tar_size = len(targ_lang.word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4935"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_tar_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = DataLoader(train_dat, batch_size = BATCH_SIZE, \n",
    "                     drop_last=True,\n",
    "                     shuffle=True)\n",
    "it = iter(dat)\n",
    "x, y, x_len = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   5, 4618,  360,    3,    4,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  5,  7,  7,  8,  5,  6,  8,  6,  8,  6,  6,  6,  8,  7,  6, 10,  6,\n",
       "         5,  6,  6,  7,  7,  8,  7,  8,  6,  7,  8,  6,  7,  5,  8,  8,  5,  5,\n",
       "         5,  7,  7,  7,  7,  7,  7,  7,  7, 10,  6,  6,  7,  7,  5,  9,  9,  7,\n",
       "         7,  7,  6,  5,  7,  8,  6,  8,  7,  7], dtype=torch.int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyData(input_tensor_train, target_tensor_train)\n",
    "val_dataset = MyData(input_tensor_val, target_tensor_val)\n",
    "\n",
    "dataset = DataLoader(train_dataset, batch_size = BATCH_SIZE, \n",
    "                     drop_last=True,\n",
    "                     shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word2idx)\n",
    "vocab_tar_size = len(targ_lang.word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataLoader(train_dataset, batch_size = BATCH_SIZE, \n",
    "                     drop_last=True,\n",
    "                     shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.gru = nn.GRU(self.embedding_dim, self.enc_units)\n",
    "        \n",
    "    def forward(self, x, lens, device):\n",
    "        # x: batch_size, max_length \n",
    "        \n",
    "        # x: batch_size, max_length, embedding_dim\n",
    "        x = self.embedding(x) \n",
    "#         print(1,x.shape)\n",
    "                \n",
    "        # x transformed = max_len X batch_size X embedding_dim\n",
    "        # x = x.permute(1,0,2)\n",
    "        x = pack_padded_sequence(x, lens) # unpad\n",
    "#         print(2,x)\n",
    "    \n",
    "        self.hidden = self.initialize_hidden_state(device)\n",
    "#         print(3, self.hidden.shape)\n",
    "        \n",
    "        # output: max_length, batch_size, enc_units\n",
    "        # self.hidden: 1, batch_size, enc_units\n",
    "        output, self.hidden = self.gru(x, self.hidden) # gru returns hidden state of all timesteps as well as hidden state at last timestep\n",
    "#         print(4,output, self.hidden.shape)\n",
    "        # pad the sequence to the max length in the batch\n",
    "        output, _ = pad_packed_sequence(output)\n",
    "#         print(5, output.shape)\n",
    "        \n",
    "        return output, self.hidden\n",
    "\n",
    "    def initialize_hidden_state(self, device):\n",
    "        return torch.zeros((1, self.batch_sz, self.enc_units)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sort batch function to be able to use with pad_packed_sequence\n",
    "def sort_batch(X, y, lengths):\n",
    "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
    "    X = X[indx]\n",
    "    y = y[indx]\n",
    "    return X.transpose(0,1), y, lengths # transpose (batch x seq) to (seq x batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 64, 1024])\n"
     ]
    }
   ],
   "source": [
    "### Testing Encoder part\n",
    "# TODO: put whether GPU is available or not\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "encoder.to(device)\n",
    "# obtain one sample from the data iterator\n",
    "it = iter(dataset)\n",
    "x, y, x_len = next(it)\n",
    "\n",
    "# sort the batch first to be able to use with pac_pack_sequence\n",
    "xs, ys, lens = sort_batch(x, y, x_len)\n",
    "\n",
    "enc_output, enc_hidden = encoder(xs.to(device), lens, device)\n",
    "\n",
    "print(enc_output.size()) # max_length, batch_size, enc_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, enc_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.enc_units = enc_units\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.gru = nn.GRU(self.embedding_dim + self.enc_units, \n",
    "                          self.dec_units,\n",
    "                          batch_first=True)\n",
    "        self.fc = nn.Linear(self.enc_units, self.vocab_size)\n",
    "        \n",
    "        # used for attention\n",
    "        self.W1 = nn.Linear(self.enc_units, self.dec_units)\n",
    "        self.W2 = nn.Linear(self.enc_units, self.dec_units)\n",
    "        self.V = nn.Linear(self.enc_units, 1)\n",
    "    \n",
    "    def forward(self, x, hidden, enc_output):\n",
    "        # enc_output original: (max_length, batch_size, enc_units)\n",
    "        # enc_output converted == (batch_size, max_length, hidden_size)\n",
    "        enc_output = enc_output.permute(1,0,2)\n",
    "        print(1,enc_output.shape)\n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        \n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        hidden_with_time_axis = hidden.permute(1, 0, 2)\n",
    "        \n",
    "        # score: (batch_size, max_length, hidden_size) # Bahdanaus's\n",
    "        # we get 1 at the last axis because we are applying tanh(FC(EO) + FC(H)) to self.V\n",
    "        # It doesn't matter which FC we pick for each of the inputs\n",
    "        score = torch.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis))\n",
    "        \n",
    "        #score = torch.tanh(self.W2(hidden_with_time_axis) + self.W1(enc_output))\n",
    "          \n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        attention_weights = torch.softmax(self.V(score), dim=1)\n",
    "        print(2, attention_weights.shape)\n",
    "        \n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * enc_output\n",
    "        context_vector = torch.sum(context_vector, dim=1)\n",
    "        print(3, context_vector.shape)\n",
    "        \n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        # takes case of the right portion of the model above (illustrated in red)\n",
    "        x = self.embedding(x)\n",
    "        print(4, x.shape)\n",
    "        \n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        #x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        # ? Looks like attention vector in diagram of source\n",
    "        x = torch.cat((context_vector.unsqueeze(1), x), -1)\n",
    "        print(5, x.shape)\n",
    "        \n",
    "        # passing the concatenated vector to the GRU\n",
    "        # output: (batch_size, 1, hidden_size)\n",
    "        output, state = self.gru(x)\n",
    "        print(6,output.shape,state.shape)\n",
    "        \n",
    "        \n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output =  output.view(-1, output.size(2))\n",
    "        print(7, output.shape)\n",
    "        \n",
    "        # output shape == (batch_size * 1, vocab)\n",
    "        x = self.fc(output)\n",
    "        print(x, x.shape)\n",
    "        \n",
    "        return x, state, attention_weights\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return torch.zeros((1, self.batch_sz, self.dec_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  torch.Size([64, 16])\n",
      "Output:  torch.Size([64, 11])\n",
      "Encoder Output:  torch.Size([10, 64, 1024])\n",
      "Encoder Hidden:  torch.Size([1, 64, 1024])\n",
      "Decoder Input:  torch.Size([64, 1])\n",
      "--------\n",
      "1 torch.Size([64, 10, 1024])\n",
      "2 torch.Size([64, 10, 1])\n",
      "3 torch.Size([64, 1024])\n",
      "4 torch.Size([64, 1, 256])\n",
      "5 torch.Size([64, 1, 1280])\n",
      "6 torch.Size([64, 1, 1024]) torch.Size([1, 64, 1024])\n",
      "7 torch.Size([64, 1024])\n",
      "tensor([[-0.0074, -0.0294, -0.0218,  ...,  0.0132, -0.0486,  0.0067],\n",
      "        [-0.0263, -0.0302, -0.0016,  ...,  0.0133, -0.0428,  0.0211],\n",
      "        [-0.0052, -0.0052, -0.0109,  ...,  0.0143, -0.0330, -0.0091],\n",
      "        ...,\n",
      "        [-0.0171, -0.0297, -0.0117,  ...,  0.0043, -0.0456, -0.0051],\n",
      "        [-0.0251, -0.0298, -0.0070,  ...,  0.0181, -0.0365, -0.0006],\n",
      "        [-0.0305, -0.0214,  0.0003,  ...,  0.0219, -0.0343,  0.0002]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>) torch.Size([64, 4935])\n",
      "Prediction:  torch.Size([64, 4935])\n",
      "Decoder Hidden:  torch.Size([1, 64, 1024])\n",
      "torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "encoder.to(device)\n",
    "# obtain one sample from the data iterator\n",
    "it = iter(dataset)\n",
    "x, y, x_len = next(it)\n",
    "\n",
    "print(\"Input: \", x.shape)\n",
    "print(\"Output: \", y.shape)\n",
    "\n",
    "# sort the batch first to be able to use with pac_pack_sequence\n",
    "xs, ys, lens = sort_batch(x, y, x_len)\n",
    "\n",
    "enc_output, enc_hidden = encoder(xs.to(device), lens, device)\n",
    "print(\"Encoder Output: \", enc_output.shape) # batch_size X max_length X enc_units\n",
    "print(\"Encoder Hidden: \", enc_hidden.shape) # batch_size X enc_units (corresponds to the last state)\n",
    "\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, units, BATCH_SIZE)\n",
    "decoder = decoder.to(device)\n",
    "\n",
    "#print(enc_hidden.squeeze(0).shape)\n",
    "\n",
    "dec_hidden = enc_hidden#.squeeze(0)\n",
    "dec_input = torch.tensor([[targ_lang.word2idx['<start>']]] * BATCH_SIZE)\n",
    "print(\"Decoder Input: \", dec_input.shape)\n",
    "print(\"--------\")\n",
    "\n",
    "for t in range(1, y.size(1)):\n",
    "    # enc_hidden: 1, batch_size, enc_units\n",
    "    # output: max_length, batch_size, enc_units\n",
    "    predictions, dec_hidden, _ = decoder(dec_input.to(device), \n",
    "                                         dec_hidden.to(device), \n",
    "                                         enc_output.to(device))\n",
    "    \n",
    "    print(\"Prediction: \", predictions.shape)\n",
    "    print(\"Decoder Hidden: \", dec_hidden.shape)\n",
    "    \n",
    "    #loss += loss_function(y[:, t].to(device), predictions.to(device))\n",
    "    \n",
    "    dec_input = y[:, t].unsqueeze(1)\n",
    "    print(dec_input.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    \"\"\" Only consider non-zero inputs in the loss; mask needed \"\"\"\n",
    "    #mask = 1 - np.equal(real, 0) # assign 0 to all above 0 and 1 to all 0s\n",
    "    #print(mask)\n",
    "    mask = real.ge(1).type(torch.cuda.FloatTensor)\n",
    "    \n",
    "    loss_ = criterion(pred, real) * mask \n",
    "    return torch.mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## TODO: Combine the encoder and decoder into one class\n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, units, BATCH_SIZE)\n",
    "\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), \n",
    "                       lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.5204\n",
      "Epoch 1 Batch 100 Loss 1.6360\n",
      "Epoch 1 Batch 200 Loss 1.4364\n",
      "Epoch 1 Batch 300 Loss 1.3506\n",
      "Epoch 1 Loss 1.5437\n",
      "Time taken for 1 epoch 163.88275265693665 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.9812\n",
      "Epoch 2 Batch 100 Loss 0.7181\n",
      "Epoch 2 Batch 200 Loss 0.7679\n",
      "Epoch 2 Batch 300 Loss 0.7228\n",
      "Epoch 2 Loss 0.8083\n",
      "Time taken for 1 epoch 160.36644506454468 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.5852\n",
      "Epoch 3 Batch 100 Loss 0.6267\n",
      "Epoch 3 Batch 200 Loss 0.5714\n",
      "Epoch 3 Batch 300 Loss 0.4395\n",
      "Epoch 3 Loss 0.4494\n",
      "Time taken for 1 epoch 161.67758560180664 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.3149\n",
      "Epoch 4 Batch 100 Loss 0.2192\n",
      "Epoch 4 Batch 200 Loss 0.2611\n",
      "Epoch 4 Batch 300 Loss 0.2966\n",
      "Epoch 4 Loss 0.2576\n",
      "Time taken for 1 epoch 161.3397660255432 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.1515\n",
      "Epoch 5 Batch 100 Loss 0.1362\n",
      "Epoch 5 Batch 200 Loss 0.1718\n",
      "Epoch 5 Batch 300 Loss 0.1483\n",
      "Epoch 5 Loss 0.1604\n",
      "Time taken for 1 epoch 161.23252367973328 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.0931\n",
      "Epoch 6 Batch 100 Loss 0.0576\n",
      "Epoch 6 Batch 200 Loss 0.1187\n",
      "Epoch 6 Batch 300 Loss 0.1479\n",
      "Epoch 6 Loss 0.1129\n",
      "Time taken for 1 epoch 162.77838134765625 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.0999\n",
      "Epoch 7 Batch 100 Loss 0.0842\n",
      "Epoch 7 Batch 200 Loss 0.0663\n",
      "Epoch 7 Batch 300 Loss 0.0651\n",
      "Epoch 7 Loss 0.0867\n",
      "Time taken for 1 epoch 163.00834035873413 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.0557\n",
      "Epoch 8 Batch 100 Loss 0.0770\n",
      "Epoch 8 Batch 200 Loss 0.0607\n",
      "Epoch 8 Batch 300 Loss 0.0909\n",
      "Epoch 8 Loss 0.0747\n",
      "Time taken for 1 epoch 174.47663021087646 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0534\n",
      "Epoch 9 Batch 100 Loss 0.0570\n",
      "Epoch 9 Batch 200 Loss 0.0738\n",
      "Epoch 9 Batch 300 Loss 0.0609\n",
      "Epoch 9 Loss 0.0663\n",
      "Time taken for 1 epoch 165.78012084960938 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0553\n",
      "Epoch 10 Batch 100 Loss 0.0282\n",
      "Epoch 10 Batch 200 Loss 0.0615\n",
      "Epoch 10 Batch 300 Loss 0.0981\n",
      "Epoch 10 Loss 0.0610\n",
      "Time taken for 1 epoch 153.58882021903992 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    \n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    for (batch, (inp, targ, inp_len)) in enumerate(dataset):\n",
    "        loss = 0\n",
    "        \n",
    "        xs, ys, lens = sort_batch(inp, targ, inp_len)\n",
    "        enc_output, enc_hidden = encoder(xs.to(device), lens, device)\n",
    "        dec_hidden = enc_hidden\n",
    "        \n",
    "        # use teacher forcing - feeding the target as the next input (via dec_input)\n",
    "        dec_input = torch.tensor([[targ_lang.word2idx['<start>']]] * BATCH_SIZE)\n",
    "        \n",
    "        # run code below for every timestep in the ys batch\n",
    "        for t in range(1, ys.size(1)):\n",
    "            predictions, dec_hidden, _ = decoder(dec_input.to(device), \n",
    "                                         dec_hidden.to(device), \n",
    "                                         enc_output.to(device))\n",
    "            loss += loss_function(ys[:, t].to(device), predictions.to(device))\n",
    "            #loss += loss_\n",
    "            dec_input = ys[:, t].unsqueeze(1)\n",
    "            \n",
    "        \n",
    "        batch_loss = (loss / int(ys.size(1)))\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                         batch,\n",
    "                                                         batch_loss.detach().item()))\n",
    "        \n",
    "        \n",
    "    ### TODO: Save checkpoint for model\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                        total_loss / N_BATCH))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
