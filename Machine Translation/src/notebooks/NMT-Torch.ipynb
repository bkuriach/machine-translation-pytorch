{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/drive/1uFJBO1pgsiFwCGIJwZlhUzaJ2srDbtw-#scrollTo=LjMMYJv85hVT\n",
    "# https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import unicodedata\n",
    "import re\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(loc = '../input/spa-eng/spa.txt', num_samples = 30000 ):\n",
    "    file = open(loc, encoding='UTF-8').read().strip().split('\\n')  \n",
    "    original_word_pairs = [[w for w in l.split('\\t')] for l in file[:num_samples]]\n",
    "    data = pd.DataFrame(original_word_pairs, columns=[\"eng\", \"es\"])\n",
    "    return data\n",
    "\n",
    "# Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "    \"\"\"\n",
    "    Normalizes latin chars with accent to their canonical decomposition\n",
    "    \"\"\"\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "    \n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\" \n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    \n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    \n",
    "    w = w.rstrip().strip()\n",
    "    \n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
    "# (e.g., 5 -> \"dad\") for each language,\n",
    "class LanguageIndex():\n",
    "    def __init__(self, lang):\n",
    "        \"\"\" lang are the list of phrases from each language\"\"\"\n",
    "        self.lang = lang\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.vocab = set()\n",
    "        \n",
    "        self.create_index()\n",
    "        \n",
    "    def create_index(self):\n",
    "        for phrase in self.lang:\n",
    "            # update with individual tokens\n",
    "            self.vocab.update(phrase.split(' '))\n",
    "            \n",
    "        # sort the vocab\n",
    "        self.vocab = sorted(self.vocab)\n",
    "\n",
    "        # add a padding token with index 0\n",
    "        self.word2idx['<pad>'] = 0\n",
    "        \n",
    "        # word to index mapping\n",
    "        for index, word in enumerate(self.vocab):\n",
    "            self.word2idx[word] = index + 1 # +1 because of pad token\n",
    "        \n",
    "        # index to word mapping\n",
    "        for word, index in self.word2idx.items():\n",
    "            self.idx2word[index] = word        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>es</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Ve.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vete.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vaya.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Váyase.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Hola.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Run!</td>\n",
       "      <td>¡Corre!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Run.</td>\n",
       "      <td>Corred.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Who?</td>\n",
       "      <td>¿Quién?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fire!</td>\n",
       "      <td>¡Fuego!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fire!</td>\n",
       "      <td>¡Incendio!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     eng          es\n",
       "0    Go.         Ve.\n",
       "1    Go.       Vete.\n",
       "2    Go.       Vaya.\n",
       "3    Go.     Váyase.\n",
       "4    Hi.       Hola.\n",
       "5   Run!     ¡Corre!\n",
       "6   Run.     Corred.\n",
       "7   Who?     ¿Quién?\n",
       "8  Fire!     ¡Fuego!\n",
       "9  Fire!  ¡Incendio!"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data()\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>es</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9766</th>\n",
       "      <td>&lt;start&gt; a bird has wings . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; los pajaros tienen alas . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6747</th>\n",
       "      <td>&lt;start&gt; that s for you . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; es para ti . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10094</th>\n",
       "      <td>&lt;start&gt; father came home . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; papa volvio a casa . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>&lt;start&gt; cook for me . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; cocina para mi . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8867</th>\n",
       "      <td>&lt;start&gt; somebody called . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; alguien llamo . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>&lt;start&gt; watch this . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; mira esto . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12576</th>\n",
       "      <td>&lt;start&gt; you re necessary . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; eres necesario . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20039</th>\n",
       "      <td>&lt;start&gt; i go to work by bus . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; voy al trabajo en autobus . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11061</th>\n",
       "      <td>&lt;start&gt; it hurts so much . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; duele tanto . . . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7027</th>\n",
       "      <td>&lt;start&gt; tom is spoiled . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; tom esta malcriado . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       eng  \\\n",
       "9766      <start> a bird has wings . <end>   \n",
       "6747        <start> that s for you . <end>   \n",
       "10094     <start> father came home . <end>   \n",
       "1626           <start> cook for me . <end>   \n",
       "8867       <start> somebody called . <end>   \n",
       "1483            <start> watch this . <end>   \n",
       "12576     <start> you re necessary . <end>   \n",
       "20039  <start> i go to work by bus . <end>   \n",
       "11061     <start> it hurts so much . <end>   \n",
       "7027        <start> tom is spoiled . <end>   \n",
       "\n",
       "                                              es  \n",
       "9766     <start> los pajaros tienen alas . <end>  \n",
       "6747                  <start> es para ti . <end>  \n",
       "10094         <start> papa volvio a casa . <end>  \n",
       "1626              <start> cocina para mi . <end>  \n",
       "8867               <start> alguien llamo . <end>  \n",
       "1483                   <start> mira esto . <end>  \n",
       "12576             <start> eres necesario . <end>  \n",
       "20039  <start> voy al trabajo en autobus . <end>  \n",
       "11061            <start> duele tanto . . . <end>  \n",
       "7027          <start> tom esta malcriado . <end>  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we do the preprocessing using pandas and lambdas\n",
    "data[\"eng\"] = data.eng.apply(lambda w: preprocess_sentence(w))\n",
    "data[\"es\"] = data.es.apply(lambda w: preprocess_sentence(w))\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 9090, 3, 4],\n",
       " [5, 9204, 3, 4],\n",
       " [5, 9082, 3, 4],\n",
       " [5, 9089, 3, 4],\n",
       " [5, 4702, 3, 4],\n",
       " [5, 2299, 1, 4],\n",
       " [5, 2304, 3, 4],\n",
       " [5, 9413, 7433, 6, 4],\n",
       " [5, 4270, 1, 4],\n",
       " [5, 4881, 1, 4]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index language using the class above\n",
    "inp_lang = LanguageIndex(data[\"es\"].values.tolist())\n",
    "targ_lang = LanguageIndex(data[\"eng\"].values.tolist())\n",
    "# Vectorize the input and target languages\n",
    "input_tensor = [[inp_lang.word2idx[s] for s in es.split(' ')]  for es in data[\"es\"].values.tolist()]\n",
    "target_tensor = [[targ_lang.word2idx[s] for s in eng.split(' ')]  for eng in data[\"eng\"].values.tolist()]\n",
    "input_tensor[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 1857, 3, 4],\n",
       " [5, 1857, 3, 4],\n",
       " [5, 1857, 3, 4],\n",
       " [5, 1857, 3, 4],\n",
       " [5, 2058, 3, 4],\n",
       " [5, 3655, 1, 4],\n",
       " [5, 3655, 3, 4],\n",
       " [5, 4815, 6, 4],\n",
       " [5, 1636, 1, 4],\n",
       " [5, 1636, 1, 4]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tensor[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_length_inp  16\n",
      "max_length_tar  11\n"
     ]
    }
   ],
   "source": [
    "# calculate the max_length of input and output tensor\n",
    "max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)\n",
    "print(\"max_length_inp \",max_length_inp)\n",
    "print(\"max_length_tar \",max_length_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(x, max_len):\n",
    "    padded = np.zeros((max_len), dtype=np.int64)\n",
    "    if len(x) > max_len: padded[:] = x[:max_len]\n",
    "    else: padded[:len(x)] = x\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inplace padding\n",
    "input_tensor = [pad_sequences(x, max_length_inp) for x in input_tensor]\n",
    "target_tensor = [pad_sequences(x, max_length_tar) for x in target_tensor]\n",
    "len(target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   5, 9090,    3,    4,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_length_inp : 16\n",
      "max_length_tar : 11\n"
     ]
    }
   ],
   "source": [
    "print(\"max_length_inp :\", max_length_inp)\n",
    "print(\"max_length_tar :\",max_length_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24000, 24000, 6000, 6000)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "# valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "# test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "# train_dataset = MyData(input_tensor_train, target_tensor_train)\n",
    "# val_dataset = MyData(input_tensor_val, target_tensor_val)\n",
    "\n",
    "# dataset = DataLoader(train_dataset, batch_size = BATCH_SIZE, \n",
    "#                      drop_last=True,\n",
    "#                      shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.from_numpy(np.array(input_tensor_train)), torch.from_numpy(np.array(target_tensor_train)))\n",
    "val_dataset = TensorDataset(torch.from_numpy(np.array(input_tensor_val)), torch.from_numpy(np.array(target_tensor_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word2idx)\n",
    "vocab_tar_size = len(targ_lang.word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataLoader(train_dataset, batch_size = BATCH_SIZE, \n",
    "                     drop_last=True,\n",
    "                     shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "#         self.gru = nn.GRU(hidden_size, hidden_size,batch_first=True)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        print(embedded.shape)\n",
    "        output = embedded\n",
    "        print(output.shape)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderRNN(\n",
       "  (embedding): Embedding(9414, 1024)\n",
       "  (lstm): LSTM(1024, 1024, batch_first=True)\n",
       ")"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Testing Encoder part\n",
    "# TODO: put whether GPU is available or not\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder = EncoderRNN(vocab_inp_size, units)\n",
    "encoder.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = DecoderRNN(units,vocab_tar_size)\n",
    "decoder = decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(dataset)\n",
    "x, y = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 16])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1048576])\n",
      "torch.Size([1, 1, 1048576])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 1024, got 1048576",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-123-0bdffbfd7ca9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0menc_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_hidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\binil kuriachan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-117-c7cb4d3ad795>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hidden)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedded\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\binil kuriachan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\binil kuriachan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    565\u001b[0m             \u001b[0mhx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 567\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    568\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[1;32mc:\\users\\binil kuriachan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;31m# type: (Tensor, Tuple[Tensor, Tensor], Optional[Tensor]) -> None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\binil kuriachan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    168\u001b[0m             raise RuntimeError(\n\u001b[0;32m    169\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[1;32m--> 170\u001b[1;33m                     self.input_size, input.size(-1)))\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_expected_hidden_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 1024, got 1048576"
     ]
    }
   ],
   "source": [
    "enc_output, enc_hidden = encoder(x.to(device), units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-fe38e9fd76b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Device\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda:0\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_inp_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Encoder' is not defined"
     ]
    }
   ],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "encoder.to(device)\n",
    "# obtain one sample from the data iterator\n",
    "it = iter(dataset)\n",
    "x, y, x_len = next(it)\n",
    "\n",
    "print(\"Input: \", x.shape)\n",
    "print(\"Output: \", y.shape)\n",
    "\n",
    "# sort the batch first to be able to use with pac_pack_sequence\n",
    "xs, ys, lens = sort_batch(x, y, x_len)\n",
    "\n",
    "enc_output, enc_hidden = encoder(xs.to(device), lens, device)\n",
    "print(\"Encoder Output: \", enc_output.shape) # batch_size X max_length X enc_units\n",
    "print(\"Encoder Hidden: \", enc_hidden.shape) # batch_size X enc_units (corresponds to the last state)\n",
    "\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, units, BATCH_SIZE)\n",
    "decoder = decoder.to(device)\n",
    "\n",
    "#print(enc_hidden.squeeze(0).shape)\n",
    "\n",
    "dec_hidden = enc_hidden#.squeeze(0)\n",
    "dec_input = torch.tensor([[targ_lang.word2idx['<start>']]] * BATCH_SIZE)\n",
    "print(\"Decoder Input: \", dec_input.shape)\n",
    "print(\"--------\")\n",
    "\n",
    "for t in range(1, y.size(1)):\n",
    "    # enc_hidden: 1, batch_size, enc_units\n",
    "    # output: max_length, batch_size, enc_units\n",
    "    predictions, dec_hidden, _ = decoder(dec_input.to(device), \n",
    "                                         dec_hidden.to(device), \n",
    "                                         enc_output.to(device))\n",
    "    \n",
    "    print(\"Prediction: \", predictions.shape)\n",
    "    print(\"Decoder Hidden: \", dec_hidden.shape)\n",
    "    \n",
    "    #loss += loss_function(y[:, t].to(device), predictions.to(device))\n",
    "    \n",
    "    dec_input = y[:, t].unsqueeze(1)\n",
    "    print(dec_input.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    \"\"\" Only consider non-zero inputs in the loss; mask needed \"\"\"\n",
    "    #mask = 1 - np.equal(real, 0) # assign 0 to all above 0 and 1 to all 0s\n",
    "    #print(mask)\n",
    "    mask = real.ge(1).type(torch.cuda.FloatTensor)\n",
    "    \n",
    "    loss_ = criterion(pred, real) * mask \n",
    "    return torch.mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## TODO: Combine the encoder and decoder into one class\n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, units, BATCH_SIZE)\n",
    "\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), \n",
    "                       lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.6137\n",
      "Epoch 1 Batch 100 Loss 1.5926\n",
      "Epoch 1 Batch 200 Loss 1.2573\n",
      "Epoch 1 Batch 300 Loss 1.1738\n",
      "Epoch 1 Loss 1.4782\n",
      "Time taken for 1 epoch 184.451566696167 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.8271\n",
      "Epoch 2 Batch 100 Loss 0.6359\n",
      "Epoch 2 Batch 200 Loss 0.7116\n",
      "Epoch 2 Batch 300 Loss 0.7174\n",
      "Epoch 2 Loss 0.7487\n",
      "Time taken for 1 epoch 199.08265566825867 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.4353\n",
      "Epoch 3 Batch 100 Loss 0.3932\n",
      "Epoch 3 Batch 200 Loss 0.3396\n",
      "Epoch 3 Batch 300 Loss 0.4074\n",
      "Epoch 3 Loss 0.4208\n",
      "Time taken for 1 epoch 359.9769802093506 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.2179\n",
      "Epoch 4 Batch 100 Loss 0.2796\n",
      "Epoch 4 Batch 200 Loss 0.2639\n",
      "Epoch 4 Batch 300 Loss 0.2271\n",
      "Epoch 4 Loss 0.2462\n",
      "Time taken for 1 epoch 340.2648720741272 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.1401\n",
      "Epoch 5 Batch 100 Loss 0.1557\n",
      "Epoch 5 Batch 200 Loss 0.1737\n",
      "Epoch 5 Batch 300 Loss 0.2161\n",
      "Epoch 5 Loss 0.1589\n",
      "Time taken for 1 epoch 323.82831716537476 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.0727\n",
      "Epoch 6 Batch 100 Loss 0.1101\n",
      "Epoch 6 Batch 200 Loss 0.1086\n",
      "Epoch 6 Batch 300 Loss 0.0984\n",
      "Epoch 6 Loss 0.1135\n",
      "Time taken for 1 epoch 370.8179612159729 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.0813\n",
      "Epoch 7 Batch 100 Loss 0.0992\n",
      "Epoch 7 Batch 200 Loss 0.0652\n",
      "Epoch 7 Batch 300 Loss 0.0944\n",
      "Epoch 7 Loss 0.0902\n",
      "Time taken for 1 epoch 386.3292818069458 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.0569\n",
      "Epoch 8 Batch 100 Loss 0.0520\n",
      "Epoch 8 Batch 200 Loss 0.0694\n",
      "Epoch 8 Batch 300 Loss 0.0682\n",
      "Epoch 8 Loss 0.0772\n",
      "Time taken for 1 epoch 386.8458721637726 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0733\n",
      "Epoch 9 Batch 100 Loss 0.0484\n",
      "Epoch 9 Batch 200 Loss 0.0585\n",
      "Epoch 9 Batch 300 Loss 0.0900\n",
      "Epoch 9 Loss 0.0685\n",
      "Time taken for 1 epoch 11077.620103597641 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0431\n",
      "Epoch 10 Batch 100 Loss 0.0553\n",
      "Epoch 10 Batch 200 Loss 0.0501\n",
      "Epoch 10 Batch 300 Loss 0.0757\n",
      "Epoch 10 Loss 0.0639\n",
      "Time taken for 1 epoch 153.1975667476654 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    \n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    for (batch, (inp, targ, inp_len)) in enumerate(dataset):\n",
    "        loss = 0\n",
    "        \n",
    "        xs, ys, lens = sort_batch(inp, targ, inp_len)\n",
    "        enc_output, enc_hidden = encoder(xs.to(device), lens, device)\n",
    "        dec_hidden = enc_hidden\n",
    "        \n",
    "        # use teacher forcing - feeding the target as the next input (via dec_input)\n",
    "        dec_input = torch.tensor([[targ_lang.word2idx['<start>']]] * BATCH_SIZE)\n",
    "        \n",
    "        # run code below for every timestep in the ys batch\n",
    "        for t in range(1, ys.size(1)):\n",
    "            predictions, dec_hidden, _ = decoder(dec_input.to(device), \n",
    "                                         dec_hidden.to(device), \n",
    "                                         enc_output.to(device))\n",
    "            loss += loss_function(ys[:, t].to(device), predictions.to(device))\n",
    "            #loss += loss_\n",
    "            dec_input = ys[:, t].unsqueeze(1)\n",
    "            \n",
    "        \n",
    "        batch_loss = (loss / int(ys.size(1)))\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                         batch,\n",
    "                                                         batch_loss.detach().item()))\n",
    "        \n",
    "        \n",
    "    ### TODO: Save checkpoint for model\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                        total_loss / N_BATCH))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
